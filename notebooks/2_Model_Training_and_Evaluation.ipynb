{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a1d5c5-21ee-4cf6-b7af-0bf18b65bcea",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Flipkart Product Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a2a85-7c3b-4c1c-9585-b595b688d541",
   "metadata": {},
   "source": [
    "### Step 2: Feature Extraction & Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f049d3-f1c1-48e4-aae2-104632d13b3c",
   "metadata": {},
   "source": [
    "### 1. Import All Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc460160-35a2-4921-bfac-ffda271b5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e893edd-1b01-4fc1-b710-52a45fbcd254",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "All required libraries for data handling, feature extraction, model training,\n",
    "and evaluation were successfully imported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc83d4c-cd6b-4137-b3ac-1651a534bb07",
   "metadata": {},
   "source": [
    "### Step 1: Load the Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382b01d5-198c-4689-a5d2-c74f26777998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_flipkart_reviews.csv\")\n",
    "\n",
    "X = df['clean_review']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b63e2a-5824-400a-b4d6-1cc22081c68d",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "- The cleaned dataset was loaded successfully.\n",
    "- The feature variable consists of preprocessed review text, while the target\n",
    "variable represents binary sentiment labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a00041-d097-4748-b332-4fce91773dd4",
   "metadata": {},
   "source": [
    "### Step 2: Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887c163c-7def-4642-a17a-0df32e1b2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c49b6-3138-4158-909d-c596ab5daca8",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "- The dataset was split into training and testing sets using an 80:20 ratio.\n",
    "- Stratified sampling was applied to preserve the original class distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af8480-562e-4cfa-9b4e-c0ca57e6b8e1",
   "metadata": {},
   "source": [
    "### Step 3: Convert Text Data into Numerical Form (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba6c9308-e598-4d50-a5cb-1e64d7519e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41720c1e-4d6e-4584-986f-30766627904e",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "- TF-IDF vectorization was used to transform textual data into numerical features.\n",
    "- The use of unigrams and bigrams helps capture meaningful word patterns present in reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0382c5-d10e-4113-91dd-8f3ad2ddb4e1",
   "metadata": {},
   "source": [
    "### Step 4: Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3edd673-cfb8-462c-97ae-bc38af7d262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b8470-ad49-44d7-923a-9a54750a71e5",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "- The Logistic Regression model was trained on TF-IDF features.\n",
    "- It is well-suited for high-dimensional sparse text data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350402d0-a44f-4c2c-9058-6822016dad0c",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e9c7a69-91d7-4bc4-8858-11127d617b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1-Score: 0.954239091876552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.49      0.62       214\n",
      "           1       0.93      0.99      0.95      1365\n",
      "\n",
      "    accuracy                           0.92      1579\n",
      "   macro avg       0.88      0.74      0.79      1579\n",
      "weighted avg       0.91      0.92      0.91      1579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression F1-Score:\", f1_lr)\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f432b997-acae-49e0-8296-5a54a87472b7",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "Logistic Regression achieved a strong F1-score, indicating effective performance\n",
    "in classifying positive and negative reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98099db3-f8b9-44a4-9448-89d46b631d8c",
   "metadata": {},
   "source": [
    "### Step 6: Train Multinomial Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bdd2d20-df2d-4c21-8867-1009d7a05415",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b09fa75-b94d-4074-90bc-cc919d5fdec8",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "- The Naive Bayes model was trained as a comparative baseline model.\n",
    "- It is computationally efficient but makes strong independence assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8aaf4a-fb9f-4ff5-87b2-d2619da2167f",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94b274f-d21b-460b-b01f-c4b907ec0c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1-Score: 0.9488795518207283\n"
     ]
    }
   ],
   "source": [
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "print(\"Naive Bayes F1-Score:\", f1_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c83aa6-b27c-417c-924c-846f8b07416c",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "Naive Bayes achieved a slightly lower F1-score compared to Logistic Regression,\n",
    "which is expected due to its simplified probabilistic assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9535cc-73a6-42a0-b012-070ab1177381",
   "metadata": {},
   "source": [
    "### Step 8: Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a71e8cd5-0dd3-4481-969b-a00916e4130d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (TF-IDF)</td>\n",
       "      <td>0.954239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes (TF-IDF)</td>\n",
       "      <td>0.948880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  F1-Score\n",
       "0  Logistic Regression (TF-IDF)  0.954239\n",
       "1          Naive Bayes (TF-IDF)  0.948880"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression (TF-IDF)\",\n",
    "        \"Naive Bayes (TF-IDF)\"\n",
    "    ],\n",
    "    \"F1-Score\": [\n",
    "        f1_lr,\n",
    "        f1_nb\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115de57d-067a-4049-b760-cd04c7c9fcdc",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "Logistic Regression outperformed Naive Bayes based on the F1-score and was selected\n",
    "as the final model for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de790c62-0903-4b97-8066-96127a3238e4",
   "metadata": {},
   "source": [
    "### Step 9: Save the Best Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e215773e-79f3-428a-a49b-72ea67bfd926",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentiment_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "\n",
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895e6d5-9e34-42ac-8dce-866867f32e16",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "The trained model and TF-IDF vectorizer were saved for reuse in real-time\n",
    "sentiment prediction through a web application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eda506-49c4-44aa-992e-4211e3447f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai_env)",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
